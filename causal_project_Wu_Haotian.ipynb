{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prioritize processing the relatively larger dataset, `oregonhie_descriptive_vars`. Use mapping columns and dummy variables to handle categorical data, and also process the date and `week_list` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_id  household_id treatment  draw_treat  draw_lottery  \\\n",
      "0        1.0      100001.0         1           7             7   \n",
      "1        2.0      100002.0         1           6             6   \n",
      "2        3.0      100003.0         0           0             2   \n",
      "3        4.0      100004.0         0           0             8   \n",
      "4        5.0      100005.0         1           7             7   \n",
      "\n",
      "   dt_notify_lottery  dt_retro_coverage  dt_app_decision postn_death  \\\n",
      "0                155                181            295.0           1   \n",
      "1                126                150              0.0           1   \n",
      "2                 28                 28              0.0           1   \n",
      "3                185                211              0.0           1   \n",
      "4                155                181              0.0           1   \n",
      "\n",
      "   numhh_list  ...  first_day_list last_day_list pobox_list self_list  \\\n",
      "0           0  ...               0             0          1         1   \n",
      "1           0  ...               0             0          0         1   \n",
      "2           0  ...               0             0          0         1   \n",
      "3           0  ...               0             0          0         1   \n",
      "4           0  ...               0             0          0         1   \n",
      "\n",
      "  week_list zip_msa_list applied_app_0 applied_app_1  approved_app_0  \\\n",
      "0         2            1             0             1               1   \n",
      "1         3            1             1             0               1   \n",
      "2         3            1             0             0               0   \n",
      "3         1            1             0             0               0   \n",
      "4         2            1             1             0               1   \n",
      "\n",
      "  approved_app_1  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def map_values(df, column, mapping, na_value=0):\n",
    "    df[column] = df[column].map(mapping).fillna(na_value)\n",
    "\n",
    "def extract_numeric(df, column, pattern):\n",
    "    df[column] = df[column].astype(str).str.extract(pattern).fillna(0).astype(int)\n",
    "\n",
    "def process_dates(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_datetime(df[col].astype(str), errors='coerce')\n",
    "        df[col] = (df[col] - df[col].min()).dt.days\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "# 读取数据集\n",
    "original_data = pd.read_stata('oregonhie_descriptive_vars.dta')\n",
    "descriptive_vars_df = pd.read_stata('oregonhie_descriptive_vars.dta')\n",
    "\n",
    "# person_id 和 household_id 不做处理\n",
    "\n",
    "# 映射列处理\n",
    "mapping_columns = {\n",
    "    'treatment': {'Selected': 1, 'Not selected': 0},\n",
    "    'postn_death': {'Alive': 1, 'Dead': 0},\n",
    "    'have_phone_list': {'Gave Phone Number': 1, 'Did NOT give phone number': 0},\n",
    "    'english_list': {'Requested English materials': 1, 'Requested materials in language other than english': 0},\n",
    "    'female_list': {'0: Male': 0, '1: Female': 1},\n",
    "    'first_day_list': {'Did NOT sign up for lottery list on first day': 0, 'Signed up for lottery list on first day': 1},\n",
    "    'last_day_list': {'Did NOT sign up for lottery list on last day': 0, 'Signed up for lottery list on last day': 1},\n",
    "    'pobox_list': {'1: POBOX': 1, '0: Not POBOX': 0},\n",
    "    'self_list': {'Signed self up': 1, 'Did NOT sign self up': 0},\n",
    "    'zip_msa_list': {'Zip code of residence in a MSA': 1, 'Zip code of residence NOT in a MSA': 0}\n",
    "}\n",
    "\n",
    "for col, mapping in mapping_columns.items():\n",
    "    map_values(descriptive_vars_df, col, mapping)\n",
    "\n",
    "# 提取数字处理\n",
    "extract_numeric(descriptive_vars_df, 'draw_treat', r'Draw (\\d+)')\n",
    "extract_numeric(descriptive_vars_df, 'draw_lottery', r'Lottery Draw (\\d+)')\n",
    "extract_numeric(descriptive_vars_df, 'week_list', r'Week (\\d+)')\n",
    "\n",
    "# 转换 applied_app 列为虚拟变量\n",
    "descriptive_vars_df['applied_app_0'] = descriptive_vars_df['applied_app'].map({\n",
    "    'Did NOT submit an application to OHP': 1,\n",
    "    'Submitted an Application to OHP': 0\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "descriptive_vars_df['applied_app_1'] = descriptive_vars_df['applied_app'].map({\n",
    "    'Did NOT submit an application to OHP': 0,\n",
    "    'Submitted an Application to OHP': 1\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "# 转换 approved_app 列为虚拟变量\n",
    "descriptive_vars_df['approved_app_0'] = descriptive_vars_df['approved_app'].map({\n",
    "    'No': 1,\n",
    "    'Yes': 0\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "descriptive_vars_df['approved_app_1'] = descriptive_vars_df['approved_app'].map({\n",
    "    'No': 0,\n",
    "    'Yes': 1\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "# 删除原始 applied_app 和 approved_app 列\n",
    "descriptive_vars_df.drop(columns=['applied_app', 'approved_app'], inplace=True)\n",
    "\n",
    "# 日期列处理\n",
    "process_dates(descriptive_vars_df, ['dt_notify_lottery', 'dt_retro_coverage', 'dt_app_decision'])\n",
    "\n",
    "# 确保 numhh_list 是字符串类型\n",
    "descriptive_vars_df['numhh_list'] = descriptive_vars_df['numhh_list'].astype(str)\n",
    "\n",
    "# 定义一个函数，将 numhh_list 的值映射到两个独立的列\n",
    "def map_numhh_list(value):\n",
    "    if value == 'signed self up':\n",
    "        return 0\n",
    "    elif value == 'signed self up + 1 additional person':\n",
    "        return 1\n",
    "    elif value == 'signed self up + 2 additional people':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0 # 如果值是意外的，默认情况\n",
    "\n",
    "# 应用函数以创建 numhh_list_1 和 numhh_list_2\n",
    "descriptive_vars_df[['numhh_list']] = descriptive_vars_df['numhh_list'].apply(map_numhh_list).apply(pd.Series)\n",
    "\n",
    "\n",
    "# ... existing code ...\n",
    "# 显示处理后的数据\n",
    "print(descriptive_vars_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When studying the impact of being selected in the lottery to apply for the OHP Standard Plan (i.e., `treatment`) on relevant outcomes, including variables such as `'female_list'`, `'have_phone_list'`, `'english_list'`, `'zip_msa_list'`, and `'postn_death'` is of great significance.\n",
    "\n",
    "The inclusion of `'female_list'` (Female: lottery list data) is due to the fact that gender may influence an individual's demand for and utilization of medical services. Females have physiological differences from males, for example, they have unique medical needs in aspects such as childbirth and gynecological diseases. This may affect their willingness to apply for the OHP Standard Plan and subsequent medical behaviors, thus influencing the research results. The reason for including `'have_phone_list'` (Gave a phone number on lottery sign up: lottery list data) is based on the consideration that individuals who provide a phone number may differ from those who do not in terms of information access and communication convenience. This may affect their efficiency in receiving information related to the OHP Standard Plan and communication with the Medicaid agency, thereby having an impact on whether to apply and the usage situation after application. `'english_list'` (Individual requested english - language materials: lottery list data) is also crucial because language preference may reflect an individual's cultural background and educational level, which may affect their understanding and acceptance of information related to the OHP Standard Plan, thus influencing the application decision - making and subsequent participation.\n",
    "\n",
    "`'zip_msa_list'` (Zip code from lottery list is a metropolitan statistical area) is selected because the residential area (whether it is a metropolitan statistical area) is closely related to the accessibility of medical resources. Metropolitan statistical areas usually have more abundant medical resources, which may affect an individual's demand for and utilization of the OHP Standard Plan, as well as their motivation to apply for this plan. The inclusion of `'postn_death'` (Death post notification date (2008 and 2009): Oregon Vital Statistics data) in the study is because an individual's survival status is a key factor influencing their participation in the Medicaid program. Individuals who died after the notification date will inevitably have different application and usage of the OHP Standard Plan compared to those who survived. This variable is crucial for accurately assessing the impact of `treatment` and can effectively avoid estimation bias caused by omitting this factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'treament'\n",
      "OLS Regression Table for Treatment:\n",
      "          Variable  Coefficient       P-value\n",
      "0      female_list    -0.016552  4.153182e-06\n",
      "1  have_phone_list     0.012724  1.483280e-02\n",
      "2     english_list    -0.061992  3.528094e-22\n",
      "3     zip_msa_list    -0.016148  1.481189e-04\n",
      "4      postn_death     0.038716  5.439683e-02\n",
      "\n",
      "OLS Regression Table for Treatment, numhh_list_1, numhh_list_2:\n",
      "                        Variable  Coefficient       P-value  Model P-value\n",
      "0           treament_female_list          NaN           NaN            NaN\n",
      "1       treament_have_phone_list          NaN           NaN   0.000000e+00\n",
      "2          treament_english_list          NaN           NaN   4.611213e-09\n",
      "3          treament_zip_msa_list          NaN           NaN            NaN\n",
      "4           treament_postn_death          NaN           NaN            NaN\n",
      "5       numhh_list_1_female_list    -0.044148  2.345795e-48            NaN\n",
      "6   numhh_list_1_have_phone_list     0.077351  1.731088e-69            NaN\n",
      "7      numhh_list_1_english_list    -0.292419  0.000000e+00            NaN\n",
      "8      numhh_list_1_zip_msa_list    -0.060576  2.549147e-64            NaN\n",
      "9       numhh_list_1_postn_death     0.123980  2.228408e-13            NaN\n",
      "10      numhh_list_2_female_list    -0.000342  3.096621e-01            NaN\n",
      "11  numhh_list_2_have_phone_list     0.000642  1.895290e-01            NaN\n",
      "12     numhh_list_2_english_list    -0.003690  7.831829e-10            NaN\n",
      "13     numhh_list_2_zip_msa_list     0.000808  4.280069e-02            NaN\n",
      "14      numhh_list_2_postn_death     0.000156  9.341062e-01            NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "# 定义回归分析函数\n",
    "def ols_regression_analysis(df, dependent_var, independent_vars):\n",
    "    try:\n",
    "        model = sm.OLS(df[dependent_var], sm.add_constant(df[independent_vars]))\n",
    "        result = model.fit()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# 定义变量\n",
    "independent_vars = ['female_list', 'have_phone_list', 'english_list', 'zip_msa_list', 'postn_death']\n",
    "dependent_vars = ['treament','numhh_list_1', 'numhh_list_2']\n",
    "\n",
    "# 存储结果\n",
    "results_treatment = {'Variable': [], 'Coefficient': [], 'P-value': []}\n",
    "results_all = {'Variable': [], 'Coefficient': [], 'P-value': [], 'Model P-value': []}\n",
    "\n",
    "# 对treatment进行回归分析\n",
    "result_treatment = ols_regression_analysis(descriptive_vars_df, 'treatment', independent_vars)\n",
    "if result_treatment is not None:\n",
    "    for var in independent_vars:\n",
    "        results_treatment['Variable'].append(var)\n",
    "        results_treatment['Coefficient'].append(result_treatment.params[var])\n",
    "        results_treatment['P-value'].append(result_treatment.pvalues[var])\n",
    "\n",
    "# 对treatment, numhh_list_1, numhh_list_2进行回归分析\n",
    "for dep_var in dependent_vars:\n",
    "    result = ols_regression_analysis(descriptive_vars_df, dep_var, independent_vars)\n",
    "    if result is not None:\n",
    "        for var in independent_vars:\n",
    "            results_all['Variable'].append(f\"{dep_var}_{var}\")\n",
    "            results_all['Coefficient'].append(result.params[var])\n",
    "            results_all['P-value'].append(result.pvalues[var])\n",
    "        results_all['Model P-value'].append(result.f_pvalue)\n",
    "    else:\n",
    "        for var in independent_vars:\n",
    "            results_all['Variable'].append(f\"{dep_var}_{var}\")\n",
    "            results_all['Coefficient'].append(None)\n",
    "            results_all['P-value'].append(None)\n",
    "        results_all['Model P-value'].append(None)\n",
    "\n",
    "# 确保所有列长度一致\n",
    "max_len = max(len(results_all['Variable']), len(results_all['Coefficient']), \n",
    "              len(results_all['P-value']), len(results_all['Model P-value']))\n",
    "\n",
    "for key in results_all.keys():\n",
    "    while len(results_all[key]) < max_len:\n",
    "        results_all[key].append(None)\n",
    "\n",
    "# 创建结果表\n",
    "regression_table_treatment = pd.DataFrame(results_treatment)\n",
    "regression_table_all = pd.DataFrame(results_all)\n",
    "\n",
    "# 显示结果表\n",
    "print(\"OLS Regression Table for Treatment:\")\n",
    "print(regression_table_treatment)\n",
    "\n",
    "print(\"\\nOLS Regression Table for Treatment, numhh_list_1, numhh_list_2:\")\n",
    "print(regression_table_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first OLS regression table for treatment, several variables show significant relationships. The coefficient of `female_list` is -0.016552 with a p - value of 4.153182e - 06, indicating that being female is negatively associated with the treatment variable. `have_phone_list` has a coefficient of 0.012724 and a p - value of 1.483280e - 02, suggesting a positive relationship with the treatment. `english_list` shows a strong negative relationship with a coefficient of -0.061992 and a p - value of 3.528094e - 22. `zip_msa_list` also has a negative coefficient of -0.016148 and a p - value of 1.481189e - 04. `postn_death` has a coefficient of 0.038716 and a p - value of 5.439683e - 02, showing a marginal positive relationship.\n",
    "\n",
    "In the second OLS regression table for treatment, `numhh_list_1`, and `numhh_list_2`, there seems to be an error as the `treament` variable in the variable names is misspelled, which might be causing the `NaN` values for the coefficients and p - values related to `treament` combinations. Regarding the `numhh_list_1` and `numhh_list_2` related variables, many show significant coefficients. For example, `numhh_list_1_female_list` has a coefficient of -0.044148 and a p - value of 2.345795e - 48, indicating a strong negative relationship between household size category 1 and being female. Similar significant relationships can be observed for other combinations with `numhh_list_1` and some with `numhh_list_2`, such as `numhh_list_2_english_list` having a coefficient of -0.003690 and a p - value of 7.831829e - 10. The Model P - value for some of the `treament` related combinations is also given, with some being highly significant like 4.611213e - 09 for `treament_english_list`, though the `NaN` values due to the misspelling need to be corrected to properly interpret the results related to the treatment variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the `stateprograms_vars_df` dataset by converting its categorical variables into dummy variables. Merge the three datasets `oregonhie_ed_vars.dta`, `oregonhie_stateprograms_vars`, and `oregonhie_descriptive_vars` using `person_id` as the matching key to create a smaller dataset, `merged_df`. Perform a balance check on this merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 stateprograms_vars_df 已经定义\n",
    "stateprograms_vars_df = pd.read_stata('oregonhie_stateprograms_vars.dta')\n",
    "# 1. 将分类列转换为字符串以允许填充\n",
    "categorical_columns = stateprograms_vars_df.select_dtypes(['category']).columns\n",
    "stateprograms_vars_df[categorical_columns] = stateprograms_vars_df[categorical_columns].astype(str)\n",
    "\n",
    "# 2. 用 0 填充缺失值\n",
    "stateprograms_vars_df.fillna(0, inplace=True)\n",
    "\n",
    "# 3. 将 'NOT enrolled'/'Enrolled' 转换为 0/1\n",
    "enrollment_columns = [\n",
    "    'ohp_all_ever_matchn_30sep2009', 'ohp_all_ever_firstn_survey0m', 'ohp_all_ever_firstn_survey6m',\n",
    "    'ohp_all_ever_inperson', 'ohp_all_ever_firstn_30sep2009', 'ohp_all_end_30sep2009',\n",
    "    'ohp_all_end_survey0m', 'ohp_all_end_survey6m', 'ohp_all_end_inperson', 'ohp_all_at_12m',\n",
    "    'ohp_std_ever_matchn_30sep2009', 'ohp_std_ever_inperson', 'ohp_std_ever_firstn_30sep2009'\n",
    "]\n",
    "\n",
    "for col in enrollment_columns:\n",
    "    stateprograms_vars_df[col] = stateprograms_vars_df[col].map({'NOT enrolled': 0, 'Enrolled': 1}).fillna(0)\n",
    "\n",
    "# 4. 从 '0 months' 格式中提取数字值\n",
    "months_columns = [\n",
    "    'ohp_all_mo_matchn_30sep2009', 'ohp_all_mo_firstn_survey0m', 'ohp_all_mo_firstn_survey6m',\n",
    "    'ohp_all_mo_inperson', 'ohp_all_mo_firstn_30sep2009', 'ohp_all_mo_12m'\n",
    "]\n",
    "\n",
    "for col in months_columns:\n",
    "    stateprograms_vars_df[col] = stateprograms_vars_df[col].astype(str).str.extract(r'(\\d+)').fillna(0).astype(int)\n",
    "\n",
    "# 5. 将 'Yes'/'No' 转换为 1/0\n",
    "yes_no_columns = [\n",
    "    'snap_ever_prenotify07', 'snap_ever_presurvey12m', 'snap_ever_matchn_30sep2009',\n",
    "    'snap_ever_firstn_survey12m', 'tanf_ever_prenotify07', 'tanf_ever_presurvey12m',\n",
    "    'tanf_ever_matchn_30sep2009', 'tanf_ever_firstn_survey12m'\n",
    "]\n",
    "\n",
    "for col in yes_no_columns:\n",
    "    stateprograms_vars_df[col] = stateprograms_vars_df[col].map({'Yes': 1, 'No': 0}).fillna(0)\n",
    "\n",
    "# 可选：如果需要，可以将其转换回分类类型\n",
    "# stateprograms_vars_df[categorical_columns] = stateprograms_vars_df[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wht\\AppData\\Local\\Temp\\ipykernel_15304\\3886653567.py:33: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(ed_vars_df[col]):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 读取数据\n",
    "original_ed_vars_df = pd.read_stata('oregonhie_ed_vars.dta')\n",
    "ed_vars_df = pd.read_stata('oregonhie_ed_vars.dta')\n",
    "\n",
    "# 确保person_id不被处理\n",
    "desc_vars_selected = descriptive_vars_df[['person_id', 'birthyear_list', 'female_list', 'self_list', \n",
    "                                          'treatment', 'numhh_list_1', 'numhh_list_2','applied_app_1',\n",
    "                                          'applied_app_0', 'dt_notify_lottery','numhh_list_1','numhh_list_2']]\n",
    "\n",
    "# 将'Yes'/'No'转换为1/0，排除'person_id'\n",
    "columns_to_transform_ed = ['any_out_pre_ed', 'num_visit_pre_cens_ed',\n",
    "                           'any_off_pre_ed', 'any_acsc_pre_ed', 'any_acsc_ed', 'any_off_ed',\n",
    "                           'any_chron_pre_ed', 'any_chron_ed', 'any_inj_pre_ed', 'any_inj_ed',\n",
    "                           'any_skin_pre_ed', 'any_skin_ed', 'any_abdo_pre_ed', 'any_abdo_ed',\n",
    "                           'any_back_pre_ed', 'any_back_ed', 'any_heart_pre_ed', 'any_heart_ed',\n",
    "                           'any_head_pre_ed', 'any_head_ed', 'any_depres_pre_ed', 'any_depres_ed',\n",
    "                           'any_psysub_pre_ed', 'any_psysub_ed', 'any_hiun_pre_ed', 'any_hiun_ed',\n",
    "                           'any_loun_pre_ed', 'any_loun_ed', 'any_visit_pre_ed', 'any_visit_ed',\n",
    "                           'any_hosp_pre_ed', 'any_hosp_ed', 'any_on_pre_ed', 'any_on_ed',\n",
    "                           'any_out_pre_ed','any_out_ed']\n",
    "\n",
    "for col in columns_to_transform_ed:\n",
    "    ed_vars_df[col] = ed_vars_df[col].map({'Yes': 1, 'No': 0}).fillna(0)\n",
    "\n",
    "# 将除columns_to_transform_ed和person_id以外的列中的缺失值赋值为0\n",
    "columns_to_exclude = columns_to_transform_ed + ['person_id']\n",
    "columns_to_fill = [col for col in ed_vars_df.columns if col not in columns_to_exclude]\n",
    "\n",
    "# 确保所有列的类别中包含0\n",
    "for col in columns_to_fill:\n",
    "    if pd.api.types.is_categorical_dtype(ed_vars_df[col]):\n",
    "        ed_vars_df[col] = ed_vars_df[col].cat.add_categories(0)\n",
    "\n",
    "ed_vars_df[columns_to_fill] = ed_vars_df[columns_to_fill].fillna(0)\n",
    "\n",
    "ed_vars_selected = ed_vars_df\n",
    "\n",
    "# Merge the two datasets on 'person_id'\n",
    "merged_df = pd.merge(desc_vars_selected, ed_vars_selected, on='person_id', how='inner')\n",
    "\n",
    "# Merge the stateprograms_vars_df with merged_df on 'person_id'\n",
    "merged_df = pd.merge(merged_df, stateprograms_vars_df, on='person_id', how='inner')\n",
    "\n",
    "\n",
    "\n",
    "# 删除 merged_df 中的重复列\n",
    "merged_df = merged_df.T.drop_duplicates().T\n",
    "\n",
    "# 将 merged_df 中的所有列转换为数值型\n",
    "merged_df = merged_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "# Now merged_df has standardized values for the specified columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the requirements in part (a), we need to process the merged dataset merged_df and perform an Ordinary Least Squares (OLS) linear regression analysis. The goal is to examine the relationship between the treatment variable and several predictors. Specifically, we will use the following variables in our regression model: any_visit_ed, num_visit_cens_ed, birthyear_list, female_list, and self_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression Results for first set of independent variables:\n",
      "  Dependent Variable Independent Variable  Coefficient       P-value  \\\n",
      "0       any_visit_ed            treatment    -0.003506  5.717272e-01   \n",
      "1  num_visit_cens_ed            treatment    -0.012248  6.970359e-01   \n",
      "2     birthyear_list            treatment     0.161946  3.031312e-01   \n",
      "3        female_list            treatment    -0.017480  7.154895e-03   \n",
      "4          self_list            treatment    -0.078290  3.917871e-88   \n",
      "\n",
      "   Balance Check Passed  \n",
      "0                  True  \n",
      "1                  True  \n",
      "2                  True  \n",
      "3                 False  \n",
      "4                 False  \n",
      "\n",
      "OLS Regression Results for second set of independent variables:\n",
      "   Dependent Variable Independent Variable  Coefficient       P-value  \\\n",
      "0        any_visit_ed            treatment     0.018805  2.725100e-03   \n",
      "1        any_visit_ed         numhh_list_1    -0.141397  4.339382e-76   \n",
      "2        any_visit_ed         numhh_list_2    -0.189291  3.895800e-03   \n",
      "3   num_visit_cens_ed            treatment     0.083670  8.712662e-03   \n",
      "4   num_visit_cens_ed         numhh_list_1    -0.606713  7.742738e-55   \n",
      "5   num_visit_cens_ed         numhh_list_2    -0.853673  1.044774e-02   \n",
      "6      birthyear_list            treatment     0.097582  5.425323e-01   \n",
      "7      birthyear_list         numhh_list_1     0.404755  3.789065e-02   \n",
      "8      birthyear_list         numhh_list_2     0.655108  6.956775e-01   \n",
      "9         female_list            treatment    -0.009990  1.311400e-01   \n",
      "10        female_list         numhh_list_1    -0.049477  8.090941e-10   \n",
      "11        female_list         numhh_list_2     0.006000  9.308696e-01   \n",
      "12          self_list            treatment     0.000608  8.392899e-01   \n",
      "13          self_list         numhh_list_1    -0.500441  0.000000e+00   \n",
      "14          self_list         numhh_list_2    -0.654175  4.203585e-96   \n",
      "\n",
      "    Balance Check Passed  \n",
      "0                   True  \n",
      "1                   True  \n",
      "2                   True  \n",
      "3                   True  \n",
      "4                   True  \n",
      "5                   True  \n",
      "6                  False  \n",
      "7                   True  \n",
      "8                  False  \n",
      "9                  False  \n",
      "10                  True  \n",
      "11                 False  \n",
      "12                 False  \n",
      "13                  True  \n",
      "14                  True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 定义回归分析函数\n",
    "def ols_regression_analysis(df, dependent_var, independent_vars):\n",
    "    try:\n",
    "        model = sm.OLS(df[dependent_var], sm.add_constant(df[independent_vars]))\n",
    "        result = model.fit()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# 定义因变量\n",
    "dependent_vars = ['any_visit_ed', 'num_visit_cens_ed', 'birthyear_list', 'female_list', 'self_list']\n",
    "\n",
    "# 定义自变量\n",
    "independent_vars_1 = ['treatment']\n",
    "independent_vars_2 = ['treatment', 'numhh_list_1', 'numhh_list_2']\n",
    "\n",
    "# 存储结果\n",
    "results_1 = {'Dependent Variable': [], 'Independent Variable': [], 'Coefficient': [], 'P-value': [], 'Balance Check Passed': []}\n",
    "results_2 = {'Dependent Variable': [], 'Independent Variable': [], 'Coefficient': [], 'P-value': [], 'Balance Check Passed': []}\n",
    "\n",
    "# 对每个因变量进行回归分析\n",
    "for dep_var in dependent_vars:\n",
    "    # 回归分析1\n",
    "    result_1 = ols_regression_analysis(merged_df, dep_var, independent_vars_1)\n",
    "    if result_1 is not None:\n",
    "        for var in independent_vars_1:\n",
    "            results_1['Dependent Variable'].append(dep_var)\n",
    "            results_1['Independent Variable'].append(var)\n",
    "            results_1['Coefficient'].append(result_1.params[var])\n",
    "            results_1['P-value'].append(result_1.pvalues[var])\n",
    "            results_1['Balance Check Passed'].append(result_1.pvalues[var] > 0.05)\n",
    "    \n",
    "    # 回归分析2\n",
    "    result_2 = ols_regression_analysis(merged_df, dep_var, independent_vars_2)\n",
    "    if result_2 is not None:\n",
    "        for var in independent_vars_2:\n",
    "            results_2['Dependent Variable'].append(dep_var)\n",
    "            results_2['Independent Variable'].append(var)\n",
    "            results_2['Coefficient'].append(result_2.params[var])\n",
    "            results_2['P-value'].append(result_2.pvalues[var])\n",
    "            results_2['Balance Check Passed'].append(result_2.pvalues[var] < 0.05)\n",
    "\n",
    "# 创建结果表\n",
    "regression_table_1 = pd.DataFrame(results_1)\n",
    "regression_table_2 = pd.DataFrame(results_2)\n",
    "\n",
    "# 显示结果表\n",
    "print(\"OLS Regression Results for first set of independent variables:\")\n",
    "print(regression_table_1)\n",
    "\n",
    "print(\"\\nOLS Regression Results for second set of independent variables:\")\n",
    "print(regression_table_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first set of OLS regression results, for the dependent variable `any_visit_ed`, the coefficient of `treatment` is -0.003506 with a p - value of 0.5717, indicating no significant impact of being selected in the lottery (treatment) on the probability of any emergency department visit. For `num_visit_cens_ed`, the coefficient of `treatment` is -0.012248 with a p - value of 0.6970, also showing no significant effect. Among other variables, `female_list` has a significant negative coefficient (-0.017480, p - value = 0.0072), suggesting that females are less likely to be affected by the treatment in terms of the outcome variables. The variable `self_list` has a highly significant negative coefficient (-0.078290, p - value close to 0), indicating that individuals who self - selected have a different response to the treatment. However, the balance check failed for `female_list` and `self_list`, which may question the reliability of the estimates related to these variables.\n",
    "\n",
    "In the second set of OLS regression results, for `any_visit_ed`, the coefficient of `treatment` is 0.018805 with a p - value of 0.0027, now showing a significant positive impact of the treatment on the probability of any emergency department visit. Regarding `num_visit_cens_ed`, the coefficient of `treatment` is 0.083670 with a p - value of 0.0087, indicating a significant positive effect on the censored number of emergency department visits. Variables like `numhh_list_1` and `numhh_list_2` also show significant coefficients for both dependent variables, highlighting the importance of household size in influencing emergency department visit outcomes. However, the balance check failed for several variables such as `birthyear_list` in relation to some comparisons, `female_list` in some cases, and `self_list` in most cases. This failure in balance check may lead to potential biases in the estimates for these variables and calls for further investigation or adjustment in the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting causalinference\n",
      "  Using cached CausalInference-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached CausalInference-0.1.3-py3-none-any.whl (51 kB)\n",
      "Installing collected packages: causalinference\n",
      "Successfully installed causalinference-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install causalinference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ATE using propensity score matching: 0.24606250994543827\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)  # 增加递归深度限制\n",
    "\n",
    "from causalinference import CausalModel\n",
    "import pandas as pd\n",
    "\n",
    "# Fill missing values\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "# Ensure all covariates are numeric\n",
    "for col in covariates:\n",
    "    merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "\n",
    "\n",
    "# 定义因变量、处理变量和协变量\n",
    "Y = merged_df['ohp_all_ever_firstn_30sep2009'].values\n",
    "D = merged_df['treatment'].values\n",
    "covariates = [\n",
    "    'birthyear_list', 'female_list', 'self_list',\n",
    "    'numhh_list_1','any_visit_pre_ed','numhh_list_2'\n",
    "]\n",
    "X = merged_df[covariates].values\n",
    "\n",
    "# 创建因果模型对象\n",
    "causal = CausalModel(Y, D, X)\n",
    "\n",
    "# 步骤1: 估计倾向得分\n",
    "causal.est_propensity_s()\n",
    "\n",
    "# 步骤2: 使用匹配法估计ATE\n",
    "causal.est_via_matching()\n",
    "\n",
    "# 获取ATE估计结果\n",
    "ATE = causal.estimates['matching']['ate']\n",
    "print(f\"Estimated ATE using propensity score matching: {ATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap standard error (ATE_SE): 0.006032206640993356\n",
      "95% Confidence Interval: (0.23423902136595495, 0.25788599852492156)\n",
      "P - value: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "se = causal.estimates['matching']['ate_se']\n",
    "\n",
    "# Compute degrees of freedom\n",
    "df_degrees = len(Y) - len(covariates) - 1\n",
    "\n",
    "# Compute t statistic\n",
    "t_stat = ATE / se\n",
    "\n",
    "# Compute two-tailed p-value\n",
    "p_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), df_degrees))\n",
    "\n",
    "t_value = stats.t.ppf(0.975, df_degrees)\n",
    "lower_bound = ATE - t_value * se\n",
    "upper_bound = ATE + t_value * se\n",
    "\n",
    "print(f\"Bootstrap standard error (ATE_SE): {se}\")\n",
    "print(f\"95% Confidence Interval: ({lower_bound}, {upper_bound})\")\n",
    "print(f\"P - value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Average Treatment Effect (ATE) is approximately 0.246. This indicates that, on average, winning the lottery boosts the probability of a user enrolling in the medical insurance program by roughly 24%. With a p - value of 0.0, there is robust statistical evidence. After controlling for covariates like birth year and phone availability, this positive ATE value shows a positive causal impact of winning the lottery on program enrollment. However, the result may be constrained by limitations such as sample representativeness, unobserved confounding factors, and statistical uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the concluding question, the **Propensity Score Matching** (PSM) technique is once more employed. The model incorporates the following variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependent variables (Y) are the **Probability of ED Visits** and the **Number of ED Visits**. The treatment variable (T) is included, and the covariates consist of `birthyear_list`, `female_list`, `self_list`, and `any_visit_pre_ed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ATE for any ED visit: 0.1354428207745668\n",
      "95% Confidence Interval for any ED visit: (0.12135624172380549, 0.1495293998253281)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.impute import SimpleImputer\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# Define the dependent variable (i) Probability of ED Visits\n",
    "Y_any_visit_ed = merged_df['any_visit_ed'].values\n",
    "# Define the dependent variable (ii) Number of ED Visits\n",
    "Y_num_visit_ed = merged_df['num_visit_cens_ed'].values\n",
    "\n",
    "# Treatment variable\n",
    "T = merged_df['ohp_all_ever_firstn_30sep2009'].values\n",
    "\n",
    "# Select covariates\n",
    "covariates = [\n",
    "    'birthyear_list', 'female_list','birthyear_list',\n",
    "    'self_list','any_visit_pre_ed'\n",
    "]\n",
    "X = merged_df[covariates].values\n",
    "\n",
    "# (i) Estimate the ATE for the probability of ED visits\n",
    "# Create a causal model object\n",
    "causal_any_visit = CausalModel(Y_any_visit_ed, T, X)\n",
    "# Step 1: Estimate the propensity scores\n",
    "causal_any_visit.est_propensity_s()\n",
    "# Step 2: Estimate the ATE using the matching method\n",
    "causal_any_visit.est_via_matching()\n",
    "# Get the ATE estimation result\n",
    "ATE_any_visit = causal_any_visit.estimates['matching']['ate']\n",
    "# Get the standard error (if available)\n",
    "try:\n",
    "    se_any_visit = causal_any_visit.estimates['matching']['ate_se']\n",
    "except KeyError:\n",
    "    print(\"Unable to obtain the standard error for the probability of ED visits. Please check the library version or the calculation process.\")\n",
    "    se_any_visit = None\n",
    "\n",
    "if se_any_visit is not None:\n",
    "    # Calculate the degrees of freedom\n",
    "    df_degrees_any_visit = len(Y_any_visit_ed) - len(covariates) - 1\n",
    "    # Get the t-distribution quantile for a 95% confidence interval\n",
    "    t_value_any_visit = stats.t.ppf(0.975, df_degrees_any_visit)\n",
    "    # Calculate the 95% confidence interval\n",
    "    lower_bound_any_visit = ATE_any_visit - t_value_any_visit * se_any_visit\n",
    "    upper_bound_any_visit = ATE_any_visit + t_value_any_visit * se_any_visit\n",
    "    print(f\"Estimated ATE for any ED visit: {ATE_any_visit}\")\n",
    "    print(f\"95% Confidence Interval for any ED visit: ({lower_bound_any_visit}, {upper_bound_any_visit})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ATE for number of ED visits: 0.5301766242343962\n",
      "95% Confidence Interval for number of ED visits: (0.4470350106085862, 0.6133182378602061)\n"
     ]
    }
   ],
   "source": [
    "# (ii) Estimate the ATE for the number of ED visits\n",
    "\n",
    "# Create a causal model object\n",
    "causal_model_ed_visits = CausalModel(Y_num_visit_ed, T, X)\n",
    "\n",
    "# Step 1: Estimate the propensity scores\n",
    "causal_model_ed_visits.est_propensity_s()\n",
    "\n",
    "# Step 2: Estimate the ATE using the matching method\n",
    "causal_model_ed_visits.est_via_matching()\n",
    "\n",
    "# Get the ATE estimation result\n",
    "ATE_ed_visits = causal_model_ed_visits.estimates['matching']['ate']\n",
    "\n",
    "# Get the standard error (if available)\n",
    "try:\n",
    "    se_ed_visits = causal_model_ed_visits.estimates['matching']['ate_se']\n",
    "except KeyError:\n",
    "    print(\"Unable to obtain the standard error for the number of ED visits. Please check the library version or the calculation process.\")\n",
    "    se_ed_visits = None\n",
    "\n",
    "if se_ed_visits is not None:\n",
    "    # Calculate the degrees of freedom\n",
    "    df_degrees_ed_visits = len(Y_num_visit_ed) - len(covariates) - 1\n",
    "    \n",
    "    # Get the t-distribution quantile for a 95% confidence interval\n",
    "    t_value_ed_visits = stats.t.ppf(0.975, df_degrees_ed_visits)\n",
    "    \n",
    "    # Calculate the 95% confidence interval\n",
    "    lower_bound_ed_visits = ATE_ed_visits - t_value_ed_visits * se_ed_visits\n",
    "    upper_bound_ed_visits = ATE_ed_visits + t_value_ed_visits * se_ed_visits\n",
    "    \n",
    "    print(f\"Estimated ATE for number of ED visits: {ATE_ed_visits}\")\n",
    "    print(f\"95% Confidence Interval for number of ED visits: ({lower_bound_ed_visits}, {upper_bound_ed_visits})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the analysis indicates that enrolling in the Medicaid program has a significant positive causal effect on an individual's emergency department (ED) visit behavior. Specifically, Medicaid enrollment not only increases the likelihood of an individual visiting the ED but also raises the actual number of ED visits during the study period. The estimated Average Treatment Effect (ATE) for the number of ED visits is 0.5302, with a 95% Confidence Interval ranging from 0.4470 to 0.6133, further reinforcing the robustness of these findings. This suggests that Medicaid coverage plays a crucial role in enhancing access to emergency medical care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Number of any ED visits**\n",
    "\n",
    "The estimated Average Treatment Effect (ATE) for the number of ED visits is **0.5302**. This indicates that, on average, Medicaid enrollment is associated with an increase of approximately 0.53 ED visits per individual. The 95% Confidence Interval for this estimate ranges from **0.4470 to 0.6133**, suggesting that we can be 95% confident that the true ATE lies within this interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Probability of any ED visits**\n",
    "\n",
    "The estimated average treatment effect (ATE) is approximately 0.1354. This indicates that, on average, enrolling in the Medicaid program increases the probability of an individual having an ED visit during the study period by about 10.86 percentage points.\n",
    "The 95% confidence interval is (0.1213, 0.1495). Since this interval does not contain 0, we can be 95% confident that there is a statistically significant positive effect of Medicaid enrollment on the likelihood of visiting the ED. In other words, the data strongly suggests that being enrolled in the Medicaid program is associated with a higher probability of making an ED visit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
